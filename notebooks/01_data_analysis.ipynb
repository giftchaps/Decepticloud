{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "89e17905",
   "metadata": {},
   "outputs": [],
   "source": "# DeceptiCloud Data Analysis\n\nThis notebook analyzes the results from DeceptiCloud experiments comparing:\n- **Adaptive**: DQN agent dynamically selecting honeypots\n- **Static**: Fixed honeypot deployment (baseline)\n\n## Objectives\n1. Load and visualize experiment results\n2. Compare adaptive vs static performance\n3. Statistical significance testing\n4. Reward trajectory analysis"
  },
  {
   "cell_type": "code",
   "id": "eb3u3f3zylw",
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport os\n\n# Set plotting style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"Libraries imported successfully\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6cwuvmajsp5",
   "source": "## 1. Load Experiment Data\n\nLoad both summary and per-timestep results from the adaptive and static experiments.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "et8vtj5f38g",
   "source": "# Load adaptive (DQN) results\nadaptive_summary = pd.read_csv('../results/results_summary.csv')\nadaptive_timestep = pd.read_csv('../results/results_per_timestep.csv')\n\n# Load static baseline results (if available)\nstatic_summary_path = '../results/static_results_summary.csv'\nstatic_timestep_path = '../results/static_results_per_timestep.csv'\n\nif os.path.exists(static_summary_path):\n    static_summary = pd.read_csv(static_summary_path)\n    static_timestep = pd.read_csv(static_timestep_path)\n    has_static = True\nelse:\n    print(\"Warning: Static baseline results not found. Run static experiment first.\")\n    print(\"To run static experiment: python scripts/run_static_experiment.py\")\n    has_static = False\n\nprint(f\"Adaptive episodes: {len(adaptive_summary)}\")\nprint(f\"Adaptive timesteps: {len(adaptive_timestep)}\")\nif has_static:\n    print(f\"Static episodes: {len(static_summary)}\")\n    print(f\"Static timesteps: {len(static_timestep)}\")\n\n# Display first few rows\nprint(\"\\nAdaptive Summary (first 5 rows):\")\nprint(adaptive_summary.head())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4ln68r6tzrc",
   "source": "## 2. Reward Trajectories\n\nVisualize how total reward per episode evolves over training.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qyhm48b3x7l",
   "source": "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Total reward per episode\nax1.plot(adaptive_summary['episode'], adaptive_summary['total_reward'], \n         marker='o', label='Adaptive (DQN)', linewidth=2)\nif has_static:\n    ax1.plot(static_summary['episode'], static_summary['total_reward'], \n             marker='s', label='Static Baseline', linewidth=2)\nax1.set_xlabel('Episode')\nax1.set_ylabel('Total Reward')\nax1.set_title('Reward per Episode')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Epsilon decay (exploration rate)\nax2.plot(adaptive_summary['episode'], adaptive_summary['epsilon'], \n         marker='o', color='orange', linewidth=2)\nax2.set_xlabel('Episode')\nax2.set_ylabel('Epsilon (Exploration Rate)')\nax2.set_title('Agent Exploration Over Time')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print summary statistics\nprint(\"Adaptive Summary Statistics:\")\nprint(f\"  Mean reward: {adaptive_summary['total_reward'].mean():.2f}\")\nprint(f\"  Std reward: {adaptive_summary['total_reward'].std():.2f}\")\nprint(f\"  Min reward: {adaptive_summary['total_reward'].min():.2f}\")\nprint(f\"  Max reward: {adaptive_summary['total_reward'].max():.2f}\")\n\nif has_static:\n    print(\"\\nStatic Summary Statistics:\")\n    print(f\"  Mean reward: {static_summary['total_reward'].mean():.2f}\")\n    print(f\"  Std reward: {static_summary['total_reward'].std():.2f}\")\n    print(f\"  Min reward: {static_summary['total_reward'].min():.2f}\")\n    print(f\"  Max reward: {static_summary['total_reward'].max():.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b6uhgdf7oo",
   "source": "## 3. Action Distribution Analysis\n\nAnalyze which honeypots the agent deployed most frequently.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pyz7gg4t4ui",
   "source": "# Count action frequencies\naction_names = {0: 'Do Nothing', 1: 'Deploy Cowrie (SSH)', 2: 'Deploy Web'}\nadaptive_actions = adaptive_timestep['action'].value_counts().sort_index()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Action distribution (bar chart)\nax = axes[0]\nactions = [action_names.get(i, f'Action {i}') for i in adaptive_actions.index]\nax.bar(actions, adaptive_actions.values, color=['gray', 'skyblue', 'coral'])\nax.set_ylabel('Frequency')\nax.set_title('Agent Action Distribution')\nax.grid(True, alpha=0.3, axis='y')\n\n# Plot 2: Action over time\nax = axes[1]\nwindow = min(50, len(adaptive_timestep) // 5)  # Moving average window\nif len(adaptive_timestep) > window:\n    adaptive_timestep['action_smooth'] = adaptive_timestep['action'].rolling(window=window).mean()\n    ax.plot(adaptive_timestep.index, adaptive_timestep['action_smooth'], linewidth=2)\n    ax.set_xlabel('Timestep')\n    ax.set_ylabel('Action (smoothed)')\n    ax.set_title(f'Action Trend (Moving Avg, window={window})')\n    ax.set_yticks([0, 1, 2])\n    ax.set_yticklabels(['Do Nothing', 'SSH', 'Web'])\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Action Distribution:\")\nfor action, count in adaptive_actions.items():\n    pct = count / len(adaptive_timestep) * 100\n    print(f\"  {action_names.get(action, f'Action {action}')}: {count} ({pct:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rthb15icz3",
   "source": "## 4. Attack Detection Analysis\n\nAnalyze SSH and web attack detection rates.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "gianvp7emr",
   "source": "# Calculate attack detection rates\nssh_attacks = adaptive_timestep['ssh_attack'].sum()\nweb_attacks = adaptive_timestep['web_attack'].sum()\ntotal_timesteps = len(adaptive_timestep)\n\n# Calculate matches (correct honeypot deployed for attack type)\nssh_matches = ((adaptive_timestep['ssh_attack'] == 1) & \n               (adaptive_timestep['current_honeypot'] == 1)).sum()\nweb_matches = ((adaptive_timestep['web_attack'] == 1) & \n               (adaptive_timestep['current_honeypot'] == 2)).sum()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Attack frequency\nax = axes[0]\nattack_counts = [ssh_attacks, web_attacks]\nax.bar(['SSH Attacks', 'Web Attacks'], attack_counts, color=['skyblue', 'coral'])\nax.set_ylabel('Number of Timesteps with Attack')\nax.set_title('Attack Type Frequency')\nax.grid(True, alpha=0.3, axis='y')\n\n# Plot 2: Match rate (honeypot matched to attack)\nax = axes[1]\nmatch_rates = []\nlabels = []\nif ssh_attacks > 0:\n    ssh_match_rate = ssh_matches / ssh_attacks * 100\n    match_rates.append(ssh_match_rate)\n    labels.append(f'SSH Match Rate\\n({ssh_matches}/{ssh_attacks})')\nif web_attacks > 0:\n    web_match_rate = web_matches / web_attacks * 100\n    match_rates.append(web_match_rate)\n    labels.append(f'Web Match Rate\\n({web_matches}/{web_attacks})')\n\nif match_rates:\n    ax.bar(labels, match_rates, color=['skyblue', 'coral'])\n    ax.set_ylabel('Match Rate (%)')\n    ax.set_title('Honeypot-Attack Match Rate')\n    ax.set_ylim([0, 100])\n    ax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Total timesteps: {total_timesteps}\")\nprint(f\"SSH attacks detected: {ssh_attacks} ({ssh_attacks/total_timesteps*100:.1f}%)\")\nprint(f\"Web attacks detected: {web_attacks} ({web_attacks/total_timesteps*100:.1f}%)\")\nif ssh_attacks > 0:\n    print(f\"SSH match rate: {ssh_matches}/{ssh_attacks} ({ssh_match_rate:.1f}%)\")\nif web_attacks > 0:\n    print(f\"Web match rate: {web_matches}/{web_attacks} ({web_match_rate:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wv0w4j94o8f",
   "source": "## 5. Statistical Comparison\n\nCompare adaptive vs static performance using statistical tests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "clxmqeeakr",
   "source": "if has_static:\n    # Comparison bar chart\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    methods = ['Adaptive (DQN)', 'Static Baseline']\n    mean_rewards = [adaptive_summary['total_reward'].mean(), \n                    static_summary['total_reward'].mean()]\n    std_rewards = [adaptive_summary['total_reward'].std(), \n                   static_summary['total_reward'].std()]\n    \n    bars = ax.bar(methods, mean_rewards, yerr=std_rewards, capsize=10, \n                   color=['skyblue', 'lightcoral'], alpha=0.8)\n    ax.set_ylabel('Mean Total Reward')\n    ax.set_title('Adaptive vs Static Performance Comparison')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, mean, std in zip(bars, mean_rewards, std_rewards):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{mean:.2f}Â±{std:.2f}',\n                ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Statistical tests\n    print(\"=\" * 60)\n    print(\"STATISTICAL COMPARISON\")\n    print(\"=\" * 60)\n    \n    # T-test (parametric)\n    t_stat, t_pval = stats.ttest_ind(adaptive_summary['total_reward'], \n                                      static_summary['total_reward'])\n    print(f\"\\nIndependent t-test:\")\n    print(f\"  t-statistic: {t_stat:.4f}\")\n    print(f\"  p-value: {t_pval:.4f}\")\n    if t_pval < 0.05:\n        print(f\"  Result: Statistically significant difference (p < 0.05)\")\n    else:\n        print(f\"  Result: No significant difference (p >= 0.05)\")\n    \n    # Mann-Whitney U test (non-parametric)\n    u_stat, u_pval = stats.mannwhitneyu(adaptive_summary['total_reward'], \n                                         static_summary['total_reward'],\n                                         alternative='two-sided')\n    print(f\"\\nMann-Whitney U test (non-parametric):\")\n    print(f\"  U-statistic: {u_stat:.4f}\")\n    print(f\"  p-value: {u_pval:.4f}\")\n    if u_pval < 0.05:\n        print(f\"  Result: Statistically significant difference (p < 0.05)\")\n    else:\n        print(f\"  Result: No significant difference (p >= 0.05)\")\n    \n    # Effect size (Cohen's d)\n    pooled_std = np.sqrt((adaptive_summary['total_reward'].std()**2 + \n                          static_summary['total_reward'].std()**2) / 2)\n    cohens_d = (adaptive_summary['total_reward'].mean() - \n                static_summary['total_reward'].mean()) / pooled_std\n    print(f\"\\nEffect Size (Cohen's d): {cohens_d:.4f}\")\n    if abs(cohens_d) < 0.2:\n        print(\"  Interpretation: Small effect\")\n    elif abs(cohens_d) < 0.5:\n        print(\"  Interpretation: Medium effect\")\n    else:\n        print(\"  Interpretation: Large effect\")\n    \nelse:\n    print(\"Skipping statistical comparison - static baseline data not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}